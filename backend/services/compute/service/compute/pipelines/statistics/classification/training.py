from celery import chord, shared_task
from sklearn.svm import SVC
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import StratifiedKFold
from sklearn.metrics import accuracy_score
from lib.util import timing_now, timing_elapsed_to_str
from lib.files import download_file
from service.compute.pipelines.base import Pipeline
from service.compute.pipelines.util import (
    get_access_token, get_storage_id_for_file, create_task_dir, delete_task_dir)
from service.compute.pipelines.statistics.util import load_features, get_xy, save_model, upload_model_archive


# ----------------------------------------------------------------------------------------------------------------------
class ClassifierTrainingPipeline(Pipeline):

    def run(self, params):

        # Validate the pipeline parameters
        self.validate_params(params)
        # Request access token from auth service
        token = get_access_token()
        # Get file storage ID from storage service
        storage_id = get_storage_id_for_file(params['file_id'], token)
        # Columns to exclude (optional parameter)
        exclude_columns = []
        if 'exclude_columns' in params.keys():
            exclude_columns = params['exclude_columns']

        # Create sub-task for each fold in the cross-validation
        header = []
        for train, test in StratifiedKFold(params['subject_labels'], n_folds=params['nr_folds'], shuffle=True):
            header.append(self.run_training_fold.subtask(
                storage_id=storage_id,
                train=list(train),
                test=list(test),
                index_column=params['index_column'],
                target_column=params['target_column'],
                exclude_columns=exclude_columns,
                token=token,
            ))

        # Create final task to be executed when the fold tasks are finished
        body = self.retrain_classifier.subtask(
            storage_id=storage_id,
            repository_id=params['repository_id'],
            nr_folds=params['nr_folds'],
            index_column=params['index_column'],
            target_column=params['target_column'],
            exlude_columns=exclude_columns,
            token=token,
        )

        # Create chord task consisting of a header listing each cross-validation fold and
        # a body task that averages the accuracies across folds and then retrains the classifier
        # using the optimal hyper-parameters
        job = chord(header=header, body=body)
        result = job.apply_async()
        return result.task_id

    @staticmethod
    @shared_task
    def run_training_fold(storage_id, train, test, index_column, target_column, exclude_columns, token):

        # Create temporary folder for storing a local copy of the input file(s) as
        # well as any intermediate files that are generated by the pipeline.
        task_dir = create_task_dir()

        try:
            # Download and import the features
            file_path = download_file(storage_id, task_dir, token)
            features = load_features(file_path, index_col=index_column)
            X, y = get_xy(features, target_column=target_column, exclude_columns=exclude_columns)

            # Start timing training procedure
            start = timing_now()

            # Start training the classifier using a grid search approach for determining
            # the optimal hyper-parameters.
            param_grid = [{
                'C': [2 ** i for i in range(-5, 15, 2)],
                'gamma': [2 ** i for i in range(-15, 4, 2)]}]
            classifier = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, scoring='accuracy')
            classifier.fit(X[train], y[train])
            y_pred = classifier.predict(X[test])
            y_true = y[test]
            accuracy = accuracy_score(y_true, y_pred)

            # Record time elapsed, accuracy and optimal hyper parameters
            time_elapsed = timing_elapsed_to_str(start)
            print('Training fold time elapsed: {}'.format(time_elapsed))
            print('Classifier accuracy: {}'.format(accuracy))
            print('Best C: {}, best gamma: {}'.format(classifier.best_params_['C'], classifier.best_params_['gamma']))

        finally:
            # Clean up task directory under any circumstances, even error
            delete_task_dir(task_dir)

        return {
            'accuracy': accuracy,
            'C': classifier.best_params_['C'],
            'gamma': classifier.best_params_['gamma'],
            'time_elapsed': time_elapsed,
        }

    @staticmethod
    @shared_task
    def retrain_classifier(outputs, storage_id, repository_id, nr_folds, index_column, target_column,
                           exclude_columns, token):

        # Extract accuracies, C and gamma values from the outputs
        accuracies = []
        Cs = []
        gammas = []
        for i in range(len(outputs)):
            accuracies.append(outputs[i]['accuracy'])
            Cs.append(outputs[i]['C'])
            gammas.append(outputs[i]['gamma'])

        # Average the accuracies
        accuracy = sum(accuracies) / nr_folds
        print('Average accuracy: {}'.format(accuracy))

        # Figure out which hyper-parameters to choose
        max_accuracy = 0.0
        max_C = 0.0
        max_gamma = 0.0
        for i in range(len(accuracies)):
            if accuracies[i] > max_accuracy:
                max_accuracy = accuracies[i]
                max_C = Cs[i]
                max_gamma = gammas[i]
        print('Max. accuracy: {}, max. C: {}, max. gamma: {}'.format(max_accuracy, max_C, max_gamma))

        # Retrain classifier on all data using the optimal hyper-parameters
        task_dir = create_task_dir()

        try:
            # Download the file and load its features
            file_path = download_file(storage_id, task_dir, token)
            features = load_features(file_path, index_col=index_column)
            X, y = get_xy(features, target_column=target_column, exclude_columns=exclude_columns)

            # Train the classifier on all features with the optimal hyper-parameters
            classifier = SVC(kernel='rbf', C=max_C, gamma=max_gamma)
            classifier.fit(X, y)

            # Save the classifier to disk and then upload it to storage service as regular file
            classifier_file_path = save_model(classifier, task_dir)
            classifier_id = upload_model_archive(classifier_file_path, repository_id, token)

        finally:
            # Delete temporary task directory even though errors may have occured
            delete_task_dir(task_dir)

        # Return average accuracy and the optimal hyper-parameters
        return {
            'accuracy': accuracy,
            'C': max_C,
            'gamma': max_gamma,
            'classifier_id': classifier_id,
        }

    @staticmethod
    def validate_params(params):

        assert 'file_id' in params.keys()
        assert params['file_id'] > 0
        assert 'subject_labels' in params.keys()
        assert len(params['subject_labels']) > 0
        assert 'index_column' in params.keys()
        assert 'target_column' in params.keys()
        assert 'nr_folds' in params.keys()
        assert params['nr_folds'] > 1
        assert 'classifier' in params.keys()
        assert params['classifier'] in ['svm-lin', 'svm-rbf']
        assert 'repository_id' in params.keys()
        assert params['repository_id'] > 0
