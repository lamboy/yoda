from celery import chord, shared_task
from sklearn.cross_validation import StratifiedKFold
from sklearn.svm import SVC
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import accuracy_score
from lib.files import download_file
from lib.util import timing_now, timing_elapsed_to_str
from service.compute.pipelines.util import get_access_token, get_storage_id_for_file
from service.compute.pipelines.base import Pipeline
from service.compute.pipelines.util import create_task_dir, delete_task_dir
from service.compute.pipelines.stats.util import load_features, get_xy, save_model, upload_model_archive


# ----------------------------------------------------------------------------------------------------------------------
class SupportVectorMachineTraining(Pipeline):

    def run(self, params):

        # Validate the pipeline parameters
        self.validate_params(params)
        # Request access token from auth service
        token = get_access_token()
        # Get file storage ID from storage service
        print('Retrieving storage ID for file {}'.format(params['file_id']))
        storage_id = get_storage_id_for_file(params['file_id'], token)
        # Columns to exclude (optional parameter)
        if 'exclude_columns' not in params.keys():
            params['exclude_columns'] = []

        # Create sub-task for each fold in the cross-validation
        print('Training classifier with {}-fold cross-validation'.format(params['nr_folds']))
        header = []
        for train, test in StratifiedKFold(params['subject_labels'], n_folds=params['nr_folds'], shuffle=True):
            header.append(self.run_training_fold.subtask((storage_id, list(train), list(test), params, token)))

        # Create final task to be executed when the fold tasks are finished
        print('Retraining classifier on all subjects')
        body = self.retrain_classifier.subtask((storage_id, params, token))

        # Create chord task consisting of a header listing each cross-validation fold and
        # a body task that averages the accuracies across folds and then retrains the classifier
        # using the optimal hyper-parameters
        job = chord(header=header, body=body)
        result = job.apply_async()
        return result.task_id

    @staticmethod
    @shared_task
    def run_training_fold(storage_id, train, test, params, token):

        # Create temporary folder for storing a local copy of the input file(s) as
        # well as any intermediate files that are generated by the pipeline.
        task_dir = create_task_dir()

        try:
            # Download and import the features
            print('Downloading file {} to directory {}'.format(storage_id, task_dir))
            file_path = download_file(storage_id, task_dir, token)
            print('Loading features from file {} with index column {}'.format(file_path, params['index_column']))
            features = load_features(file_path, index_col=params['index_column'])
            print('Converting to Numpy array with target column {}, excluding {}'.format(
                params['target_column'], params['exclude_columns']))
            X, y = get_xy(features, target_column=params['target_column'], exclude_columns=params['exclude_columns'])

            # Convert kernel parameter from unicode to str. For some reason SVC() does
            # not support unicode parameters.
            kernel = str(params['kernel'])

            # Start timing training procedure
            start = timing_now()

            # Start training the classifier using a grid search approach for determining
            # the optimal hyper-parameters.
            print('Start training classifier using grid search')
            param_grid = [{
                'C': [2 ** i for i in range(-5, 15, 2)],
                'gamma': [2 ** i for i in range(-15, 4, 2)]}]
            classifier = GridSearchCV(SVC(kernel=kernel), param_grid=param_grid, scoring='accuracy')
            classifier.fit(X[train], y[train])
            y_pred = classifier.predict(X[test])
            y_true = y[test]
            accuracy = accuracy_score(y_true, y_pred)

            # Record time elapsed, accuracy and optimal hyper parameters
            time_elapsed = timing_elapsed_to_str(start)
            print('Classifier training fold time elapsed: {}'.format(time_elapsed))
            print('Classifier accuracy: {} (C: {}, gamma: {})'.format(
                accuracy, classifier.best_params_['C'], classifier.best_params_['gamma']))

        finally:
            # Clean up task directory under any circumstances, even error
            print('Cleaning up task directory')
            delete_task_dir(task_dir)

        return {
            'accuracy': accuracy,
            'C': classifier.best_params_['C'],
            'gamma': classifier.best_params_['gamma'],
            'time_elapsed': time_elapsed,
        }

    @staticmethod
    @shared_task
    def retrain_classifier(outputs, storage_id, params, token):

        # Extract accuracies, C and gamma values from the outputs
        accuracies = []
        Cs = []
        gammas = []
        for i in range(len(outputs)):
            accuracies.append(outputs[i]['accuracy'])
            Cs.append(outputs[i]['C'])
            gammas.append(outputs[i]['gamma'])

        # Average the accuracies
        accuracy = sum(accuracies) / params['nr_folds']
        print('Average accuracy: {}'.format(accuracy))

        # Figure out which hyper-parameters to choose
        max_accuracy = 0.0
        max_C = 0.0
        max_gamma = 0.0
        for i in range(len(accuracies)):
            if accuracies[i] > max_accuracy:
                max_accuracy = accuracies[i]
                max_C = Cs[i]
                max_gamma = gammas[i]
        print('Max. accuracy: {}, max. C: {}, max. gamma: {}'.format(max_accuracy, max_C, max_gamma))

        # Retrain classifier on all data using the optimal hyper-parameters
        task_dir = create_task_dir()

        # Convert kernel parameter from unicode to str. For some reason SVC() does
        # not support unicode parameters.
        kernel = str(params['kernel'])

        try:
            # Download the file and load its features
            file_path = download_file(storage_id, task_dir, token)
            features = load_features(file_path, index_col=params['index_column'])
            X, y = get_xy(features, target_column=params['target_column'], exclude_columns=params['exclude_columns'])

            # Train the classifier on all features with the optimal hyper-parameters
            classifier = SVC(kernel=kernel, C=max_C, gamma=max_gamma)
            classifier.fit(X, y)

            # Save the classifier to disk and then upload it to storage service as regular file
            classifier_file_path = save_model(classifier, task_dir)
            classifier_id = upload_model_archive(classifier_file_path, params['repository_id'], token)

        finally:
            # Delete temporary task directory even though errors may have occurred
            delete_task_dir(task_dir)

        # Return average accuracy and the optimal hyper-parameters
        return {
            'accuracy': accuracy,
            'C': max_C,
            'gamma': max_gamma,
            'classifier_id': classifier_id,
        }

    @staticmethod
    def validate_params(params):

        print('Validating parameters')
        assert 'file_id' in params.keys()
        assert params['file_id'] > 0
        assert 'subject_labels' in params.keys()
        assert len(params['subject_labels']) > 0
        assert 'index_column' in params.keys()
        assert 'target_column' in params.keys()
        assert 'nr_folds' in params.keys()
        assert params['nr_folds'] > 1
        assert 'kernel' in params.keys()
        assert params['kernel'] in ['linear', 'rbf']
        assert 'repository_id' in params.keys()
        assert params['repository_id'] > 0
