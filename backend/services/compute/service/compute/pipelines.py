import os
import shutil
import requests
import logging
from flask import Config
from celery import chord, shared_task
from sklearn.svm import SVC
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import StratifiedKFold
from sklearn.metrics import accuracy_score
from lib.util import generate_string, service_uri, timing_now, timing_elapsed_to_str
from lib.authentication import login_header, token_header
from util import load_features, get_xy

config = Config(None)
config.from_object('service.compute.settings')

logger = logging.getLogger(__name__)


# ----------------------------------------------------------------------------------------------------------------------
class Pipeline(object):

    def run(self, params):
        raise NotImplementedError()


# ----------------------------------------------------------------------------------------------------------------------
class ClassifierTrainingPipeline(Pipeline):
    """
    Trains a classifier and returns its ID as well as some additional meta-
    information about its accuracy.
    """
    def run(self, params):

        # Validate the pipeline parameters
        self.validate_params(params)
        # Request access token from auth service
        token = self.get_access_token()
        # Get file storage ID from storage service
        storage_id = self.get_file_storage_id(params['file_id'], token)
        # Columns to exclude (optional parameter)
        exclude_columns = []
        if 'exclude_columns' in params.keys():
            exclude_columns = params['exclude_columns']

        # Create sub-task for each fold in the cross-validation
        tasks = []
        for train, test in StratifiedKFold(params['subject_labels'], n_folds=params['nr_folds'], shuffle=True):
            # Convert train/test indices to regular lists otherwise they can't be serialized
            train, test = list(train), list(test)
            tasks.append(self.run_fold.subtask(
                (storage_id, train, test, params['index_column'], params['target_column'], exclude_columns, token)))

        # Create chord job that trains a classifier for each file ID and at the
        # end builds a task result object containing the output results.
        job = chord(header=tasks, body=self.build_task_result.subtask((params['nr_folds'],)))
        result = job.apply_async()

        return result.task_id

    @staticmethod
    def get_access_token():
        logger.debug('Requesting access token')
        response = requests.post(
            '{}/tokens'.format(service_uri('auth')), headers=login_header(
                config['WORKER_USERNAME'],
                config['WORKER_PASSWORD']))
        return response.json()['token']

    @staticmethod
    def get_file_storage_id(file_id, token):
        logger.debug('Getting file storage ID')
        response = requests.get('{}/files/{}'.format(service_uri('storage'), file_id), headers=token_header(token))
        storage_id = response.json()['storage_id']
        logger.debug('File storage ID found: {}'.format(storage_id))
        return storage_id

    @staticmethod
    @shared_task
    def run_fold(storage_id, train, test, index_column, target_column, exclude_columns, token):

        # Create temporary folder for storing a local copy of the input file(s) as
        # well as any intermediate files that are generated by the pipeline.
        task_dir = create_task_dir()

        try:
            # Download the file to local task directory
            logger.debug('Downloading and saving file to local task directory')
            response = requests.get(
                '{}/downloads/{}'.format(service_uri('storage'), storage_id), headers=token_header(token))
            file_path = os.path.join(task_dir, storage_id)
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(1024*1024):
                    f.write(chunk)
            logger.debug('File {} saved'.format(file_path))

            # Load features into memory
            logger.debug('Loading features')
            features = load_features(file_path, index_col=index_column)
            X, y = get_xy(features, target_column=target_column, exclude_columns=exclude_columns)

            # Define grid of hyper-parameter values to try
            param_grid = [{
                'C': [2 ** i for i in range(-5, 15, 2)],
                'gamma': [2 ** i for i in range(-15, 4, 2)]}]

            # Start training the classifier using a grid search approach for determining
            # the optimal hyper-parameters.
            logger.debug('Starting classifier training')
            start = timing_now()
            classifier = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, scoring='accuracy', verbose=1)
            classifier.fit(X[train], y[train])
            y_pred = classifier.predict(X[test])
            y_true = y[test]

            # Calculate classification accuracy
            accuracy = accuracy_score(y_true, y_pred)

            # Log fold accuracy and time to complete
            logger.debug('Classifier accuracy {}'.format(accuracy))
            logger.debug('Fold finished after {}'.format(timing_elapsed_to_str(start)))

        finally:
            # Clean up task directory under any circumstances, even error
            delete_task_dir(task_dir)

        # Return the accuracy of the classifier
        return accuracy

    @staticmethod
    @shared_task
    def build_task_result(accuracies, nr_folds):
        accuracy = sum(accuracies) / nr_folds
        logger.debug('Average accuracy: {}'.format(accuracy))
        return accuracy

    @staticmethod
    def validate_params(params):
        assert 'file_id' in params.keys()
        assert params['file_id'] > 0
        assert 'subject_labels' in params.keys()
        assert len(params['subject_labels']) > 0
        assert 'index_column' in params.keys()
        assert 'target_column' in params.keys()
        assert 'nr_folds' in params.keys()
        assert params['nr_folds'] > 0
        assert 'classifier' in params.keys()
        assert 'name' in params['classifier'].keys()
        assert params['classifier']['name'] in ['svm-lin', 'svm-rbf']


# ----------------------------------------------------------------------------------------------------------------------
class ClassificationPipeline(Pipeline):
    """
    Runs a trained classifier on one or more test observations. The classifier
    must have been trained previously via the ClassifierTrainingPipeline. This
    pipeline will have saved a classifier to disk.
    """
    def run(self, params):
        print('Running classification')
        return True


# ----------------------------------------------------------------------------------------------------------------------
def create_task_dir():
    task_dir = '/tmp/workers/task-{}'.format(generate_string())
    if os.path.isdir(task_dir):
        raise RuntimeError('Directory {} already exists'.format(task_dir))
    logger.debug('Creating directory {}'.format(task_dir))
    os.makedirs(task_dir)
    return task_dir


# ----------------------------------------------------------------------------------------------------------------------
def delete_task_dir(task_dir):
    if not os.path.isdir(task_dir):
        raise RuntimeError('Directory {} does not exist'.format(task_dir))
    logger.debug('Deleting directory {}'.format(task_dir))
    shutil.rmtree(task_dir)
